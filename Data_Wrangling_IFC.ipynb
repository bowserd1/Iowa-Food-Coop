{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "env_variables = dotenv_values('Ignore.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to SQL database\n",
    "mydb = mysql.connector.connect(\n",
    "  host=env_variables['HOST'],\n",
    "  user=env_variables['USER'],\n",
    "  password=env_variables['PASSWORD'],\n",
    "  port=env_variables['PORT']\n",
    ")\n",
    "\n",
    "print(mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling data from sql database\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\"USE ifcom_prod\")\n",
    "cursor.execute(\"SELECT c.IDCyc, c.WhenStartPickup, c.IDMemb, c.WhenReg, c.Addr1, c.Addr2, c.City, c.St, c.Zip, c.CDLocLast, l.NumLogins FROM (SELECT IDCyc, WhenStartPickup, IDMemb, WhenReg, Addr1, Addr2, City, St, Zip, CDLocLast FROM Cyc CROSS JOIN Memb) c LEFT JOIN (SELECT IDMemb, COUNT(IDMemb) AS NumLogins FROM Login GROUP BY IDMemb) l ON c.IDMemb = l.IDMemb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cursor.fetchall()\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "member_df = pd.DataFrame(results, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows returned: {len(results)}\")\n",
    "print(f\"Column names: {[description[0] for description in cursor.description]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=env_variables['HOST'],\n",
    "  user=env_variables['USER'],\n",
    "  password=env_variables['PASSWORD'],\n",
    "  port=env_variables['PORT']\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\"USE ifcom_prod\")\n",
    "cursor.execute(\"SELECT IDMemb, Addr1,Addr2, City,St,Zip,CDLocLast, CkFounder, HowHear, CDRegMemb FROM Memb\")\n",
    "results = cursor.fetchall()\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "member_names_df = pd.DataFrame(results, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.read_csv('producer-sales-report-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns that aren't needed\n",
    "member_names_df.drop([\"Addr1\",\"Addr2\", \"City\", \"St\",\"Zip\", \"CDLocLast\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_names_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comnbining Membership info here so that there is a row for every customer for every ordering period.\n",
    "#It is now ready to merge onto the sales data.\n",
    "customer_df = member_df.merge(member_names_df, how='left', on = [\"IDMemb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulled data in the middle of a cycle. Deleting all data in cycles after 334 so I'm only evaluating complete cycles.\n",
    "customer_df = customer_df[customer_df['IDCyc']<335]\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping more columns that aren't needed.\n",
    "sales_df = initial_df.drop(['IDVty','FeeCoop','TaxSale','Producer','CustEmail','CustPhone','NameProduct','CustomerName','QtyDeliv','FeeCoopForgiv'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't want to look at sales onsite. Only web sales\n",
    "sales_df=sales_df[sales_df['saleSource']!='onsite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data was pulled in the middle of a cycle. Getting rid of everything after cycle id 334.\n",
    "sales_df = sales_df[sales_df['IDCyc'] <= 334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By making a pivot table here, I am aggregating each customer's purchases by category by week purchased. I will then be able to add each\n",
    "# category as a feature to the dataframe with how much each customer spent on each category each ordering period.\n",
    "cats_to_cols = sales_df.pivot_table(index=['IDCyc','IDMemb'], values = 'SaleNom',columns = 'NameCat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_to_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_to_cols.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_to_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making another pivot table that adds the total sales for each customer during each ordering period. I will merge this back in to the main dataframe later.\n",
    "customer_sales_by_cycle_df = pd.pivot_table(sales_df, values='SaleNom', index =['IDMemb','IDCyc'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_sales_by_cycle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging data backinto the main dataframe.\n",
    "combined_df = customer_df.merge(customer_sales_by_cycle_df, how = 'left', on = ['IDMemb','IDCyc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df has all members in it, even those who have never ordered. Need to think about removing people if they have never ordered.\n",
    "\n",
    "new_df = combined_df.merge(cats_to_cols, how = 'left', on = ['IDMemb','IDCyc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see how many unique customer ID's we have, and of those how many have ordered over the last 2 years.\n",
    "total_members=len(new_df['IDMemb'].unique())\n",
    "customers_ordering=len(new_df[new_df['SaleNom']>0]['IDMemb'].unique())\n",
    "print(f\"The IFC has {total_members} total members and {customers_ordering} of them have ordered in the last two years.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing for calculating distance to pick up. Need to clean up the address info.\n",
    "new_df['St'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing typos when peopel typed in their state.\n",
    "new_df['St'].replace('IO','IA',inplace = True)\n",
    "new_df['St'].replace('Ia','IA',inplace = True)\n",
    "new_df['St'].replace('ia','IA',inplace = True)\n",
    "new_df['St'].replace('22','IA',inplace = True)\n",
    "new_df['St'].replace('I','IA',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['St'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the only people who have ordered who are not from Iowa.\n",
    "new_df[(new_df['St']!='IA') & new_df['SaleNom']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping all members not from Iowa who have never ordered. This should make it easier to compute addresses and distances in the next step.\n",
    "new_df=new_df.drop(new_df[new_df['St'].isin(['CO', 'MN', 'SD', 'TN', 'AR', 'MO', 'FL', 'PO', 'AK', 'NE',\n",
    "       'NY', 'IL', 'AZ', 'SO', 'NV', 'WI', 'PA', 'KS', 'TX', 'AL',\n",
    "       'WA', 'XT', 'XE', 'OR', 'IS', 'MI', 'GA', 'AI', 'RI', '14',\n",
    "       'MD', 'NJ'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I got further along, apartment numbers did not work when I tried to find their geolocation. This code will remove\n",
    "# the apartment numbers from the addresses\n",
    "new_df['Addr1'] = new_df['Addr1'].str.split('#').str[0]\n",
    "new_df['full_address'] = new_df.Addr1 + ',' + new_df.City + ',' + new_df.St + ',' + new_df.Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the locations where members can pick up their orders.\n",
    "sites = {'FRAN': (41.61144913179401, -93.68691528533463),\n",
    "\"ANK\" :(41.72639503101638, -93.58202826441813),\n",
    "\"HOME\" :('nan'),\n",
    "\"WDM\" :(41.58160655660526, -93.83719844907307),\n",
    "\"IND\" :(41.364019620478196, -93.56060397936696),\n",
    "\"PAN\" :(41.653588359660176, -94.32091117790932),\n",
    "\"HILL\" :(41.60142613460194, -93.5138259018194),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sites to a dataframe\n",
    "sites_df = pd.DataFrame(sites)\n",
    "sites_df = sites_df.T\n",
    "sites_df.rename({0:'Pickup_lat',1:'Pickup_long'},axis = 1,inplace = True)\n",
    "sites_df.reset_index(inplace=True)\n",
    "sites_df.rename({'index': 'CDLocLast'},axis=1,inplace = True)\n",
    "sites_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shrinking my dataframe to only get every member once time. This way I only have to calculate each distance one time.\n",
    "geocoding_df = new_df[new_df['IDCyc'] == new_df['IDCyc'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = env_variables['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import GoogleV3\n",
    "import requests\n",
    "geolocator = GoogleV3(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to calculate the lat and long of each address.\n",
    "def geocode_address(address):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if data['status'] == 'OK':\n",
    "        lat = data['results'][0]['geometry']['location']['lat']\n",
    "        lng = data['results'][0]['geometry']['location']['lng']\n",
    "        return lat, lng\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting latitude and longitude coordinates for each address in dataframe.\n",
    "geocoding_df[['latitude', 'longitude']] = geocoding_df['full_address'].apply(geocode_address).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the sites dataframe so we can calulate distance between pickup location and each customer's address.\n",
    "geocoding_df = geocoding_df.merge(sites_df, how = 'left', on ='CDLocLast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoding_df=geocoding_df.astype({'latitude':'float','longitude':'float', 'Pickup_lat':'float', 'Pickup_long':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoding_df[geocoding_df['latitude'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoding_df=geocoding_df[(geocoding_df['IDMemb']!=1347) & (geocoding_df['IDMemb']!=1351)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining distance function to calc each customer's distance to pickup\n",
    "def distance(x,y):\n",
    "    try:\n",
    "        result = geopy.distance.geodesic(x,y).miles\n",
    "    except ValueError:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running function\n",
    "geocoding_df['Distance_to_pickup']=geocoding_df.apply(lambda x: distance((x.latitude, x.longitude),(x.Pickup_lat,x.Pickup_long)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoding_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the distances to pickup back onto our main dataframe.\n",
    "df = new_df.merge(geocoding_df[['IDMemb', 'latitude', 'longitude', 'Pickup_lat',\n",
    "       'Pickup_long', 'Distance_to_pickup']], how = 'left', on = 'IDMemb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting When registered as a dateteime object.\n",
    "df['WhenReg'] = pd.to_datetime(df['WhenReg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtract when the member registered from the pickup day of the cycle to see how long they have been a member.\n",
    "df['Years_member'] = (df['WhenStartPickup'] - df['WhenReg'])/datetime.timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fixes the dataframe since currently it has cycle created for every member, even if they hadn't signed up yet. Now, we can delete all rows\n",
    "#where the member hadn't registered yet.\n",
    "df = df[df['Years_member']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles = df['IDCyc'].unique()\n",
    "dates = df['WhenStartPickup'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cycle_num_df=pd.DataFrame()\n",
    "date_cycle_num_df['IDCyc'] = cycles\n",
    "date_cycle_num_df['WhenStartPickup']=dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cycle_num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding quarters to the data\n",
    "date_cycle_num_df['quarter'] = pd.PeriodIndex(date_cycle_num_df.WhenStartPickup, freq='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding months to the data\n",
    "date_cycle_num_df['month'] = pd.DatetimeIndex(date_cycle_num_df['WhenStartPickup']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cycle_num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holiday column. Starting with all 0's, which means no holiday. 1 will be just before a major holiday, 2 will\n",
    "#will mean just after a holiday. Only for holidays within 10 days of pickup. Chose to use the following holidays:\n",
    "#New Years, Valentine's Day, Memorial Day, Independence Day, Labor Day, Thanksgiving, Christmas and New Year's\n",
    "date_cycle_num_df['holiday'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cycle_num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cycle_num_df.at[6,'holiday']=2 # after Valentines\n",
    "date_cycle_num_df.at[7,'holiday']=1 # before Valentines\n",
    "date_cycle_num_df.at[10,'holiday']=2 #after Christmas\n",
    "date_cycle_num_df.at[11,'holiday']=1 #before Christmas\n",
    "date_cycle_num_df.at[12,'holiday']=2 #after Thanksgiving\n",
    "date_cycle_num_df.at[13,'holiday']=1 #before Thanksgiving\n",
    "date_cycle_num_df.at[18,'holiday']=2 #after Labor Day\n",
    "date_cycle_num_df.at[22,'holiday']=2 # after July 4\n",
    "date_cycle_num_df.at[23,'holiday']=1 # before July 4\n",
    "date_cycle_num_df.at[25,'holiday']=2 #after Memorial Day\n",
    "date_cycle_num_df.at[29,'holiday']=1 # before Easter\n",
    "date_cycle_num_df.at[28,'holiday']=2 #after Easter\n",
    "date_cycle_num_df.at[32,'holiday']=2 # after Valentines\n",
    "date_cycle_num_df.at[33,'holiday']=1 # before Valentines\n",
    "date_cycle_num_df.at[36,'holiday']=2 #after Christmas\n",
    "date_cycle_num_df.at[37,'holiday']=1 #before Christmas\n",
    "date_cycle_num_df.at[38,'holiday']=2 #after Thanksgiving\n",
    "date_cycle_num_df.at[39,'holiday']=1 #before Thanksgiving\n",
    "date_cycle_num_df.at[44,'holiday']=2 #after Memorial Day\n",
    "date_cycle_num_df.at[49,'holiday']=1 # before July 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cycle_num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the holiday info onto the main dataframe\n",
    "df = df.merge(date_cycle_num_df, how='left', on = ['IDCyc', 'WhenStartPickup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/emilydanielbowser/Documents/Iowa Food Coop/Data/Intermediate Data/Wrangled_data'\n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
